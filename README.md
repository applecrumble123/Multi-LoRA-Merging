# Multi-LoRA-Merging

## Dataset

### SQuADv2 Dataset
The Stanford Question Answering Dataset (SQuADv2) is a widely used benchmark for evaluating question-answering systems. It comprises over 150,000 questions paired with context paragraphs extracted from Wikipedia, covering a broad range of topics. A key distinction from its predecessor, SQuADv1, is the inclusion of unanswerable questions. These are designed to challenge models to not only extract answers from the provided context but also identify instances where no answer exists. This makes SQuADv2 a robust benchmark for assessing generalization, reasoning capabilities, and contextual understanding of large language models (LLMs). 

### MedMCQA Dataset
The MedMCQA (Medical Multiple-Choice Question Answering) dataset is a large-scale benchmark designed to evaluate models on medical question-answering tasks. It comprises over 300,000 multiple-choice questions spanning diverse medical disciplines such as pharmacology, physiology, anatomy, and pathology. Each question is accompanied by four answer options, with one correct answer, replicating the format of real-world medical examinations. The dataset poses domain-specific challenges by capturing the complexity of medical knowledge, requiring models to comprehend clinical context and apply medical reasoning. It includes a wide variety of question types, ranging from fact-based queries to scenario-driven reasoning, making it ideal for assessing a model's ability to generalize and solve problems effectively. Curated from publicly available medical resources, the dataset features a realistic distribution of topics and difficulty levels. 

### Medical Corpus
General Medical articles. 79 articles were used.

## Conversion of Dataset

## Training

## Evaluating
